{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cfeb114-1bbc-4c57-88fa-2d72da77a56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# get parquet file from here: \n",
    "# Current data source in a S3 bucket: sneakedreferences/processable-references/run_2024_08_19/2024_8_19T15_18_19.parquet\n",
    "# down\n",
    "# The parquet file is downloaded to the local machine\n",
    "FILENAME = \"2024_8_19T15_18_19.parquet\"\n",
    "def read_data(parquet_filename = FILENAME):\n",
    "    \"\"\"Reads parquet file and returns a dataframe\"\"\"\n",
    "    print(f\"{read_data.__name__}: {read_data.__doc__}\")\n",
    "    df = pd.read_parquet(parquet_filename)\n",
    "    return df\n",
    "\n",
    "def rearrange(issn):\n",
    "    \"\"\"Re-arranges ISSN datastructure to a more readable format\"\"\"\n",
    "    data = list(map(lambda x: (f\"{x[0][1]}\", f\"{x[1][1]}\"),issn))\n",
    "    return data\n",
    "\n",
    "def split_issn(issn):\n",
    "    \"\"\"Splits the datastructure into its component issns\"\"\"\n",
    "    e_issn = None\n",
    "    p_issn = None\n",
    "    for i in issn:\n",
    "        if \"print\" in i:\n",
    "            p_issn = i[1]\n",
    "        elif \"electronic\" in i:\n",
    "            e_issn = i[1]\n",
    "    return p_issn, e_issn\n",
    "\n",
    "def fix_issn(row):\n",
    "    \"\"\"Splits the original structure from the filename to a more readable format\"\"\"\n",
    "    issn = row['issn']\n",
    "    first_pass_issn = rearrange(issn)\n",
    "    p_issn, e_issn = split_issn(first_pass_issn)\n",
    "    return p_issn, e_issn\n",
    "\n",
    "def separate_container_title(data):\n",
    "    \"\"\"Converting type to allow for easier grouping\"\"\"\n",
    "    title = data\n",
    "    if isinstance(data, np.ndarray):\n",
    "        title = \", \".join(data.tolist())\n",
    "    return title\n",
    "\n",
    "def prepare_data_frame(filename = FILENAME):\n",
    "    \"\"\"generates dataframe, processes ISSNs, adds counts\"\"\"\n",
    "    print(f\"{prepare_data_frame.__name__}: {prepare_data_frame.__doc__}\")\n",
    "    df = read_data(filename)\n",
    "    df[['print_issn', 'electronic_issn']] = df.apply(fix_issn, axis = 1, result_type='expand')\n",
    "    df['separated_tokens'] = df.token_vocabulary.apply(lambda x: \", \".join(sorted(x)))\n",
    "    df['container_title'] = df.container_title.apply(separate_container_title)\n",
    "    df['ref_pge'] = df.apply(lambda x: x['cleaned_references_length']/x['total_reference_length'], axis=1)\n",
    "    df.drop(columns=['issn'], inplace=True)\n",
    "    # group counts\n",
    "    df['token_counts_by_print_issn'] = df.groupby(['separated_tokens', 'print_issn'])['DOI'].transform('count')\n",
    "    df['token_counts_by_electronic_issn'] = df.groupby(['separated_tokens', 'electronic_issn'])['DOI'].transform('count')\n",
    "    return df\n",
    "\n",
    "def in_title(row):\n",
    "    \"\"\"checks to see if the token vocabulary is part of the book title\"\"\"\n",
    "    tf = \"No\"\n",
    "    title_flag = []\n",
    "    title = row['title']\n",
    "    if (isinstance(row['token_vocabulary'], np.ndarray)) and title:\n",
    "        for i in row['token_vocabulary']:\n",
    "            if i.lower() in title.lower():\n",
    "                title_flag.append('Yes')\n",
    "    if 'Yes' in title_flag:\n",
    "        tf = \"Yes\"\n",
    "    return tf\n",
    "    \n",
    "def in_container_title(row):\n",
    "    \"\"\"checks to see if the token vocabulary is part of the container title\"\"\"\n",
    "    tf = \"No\"\n",
    "    title_flag = []\n",
    "    title = row['container_title']\n",
    "    if (isinstance(row['token_vocabulary'], np.ndarray)) and title:\n",
    "        for i in row['token_vocabulary']:\n",
    "            if i.lower() in title.lower():\n",
    "                title_flag.append('Yes')\n",
    "    if 'Yes' in title_flag:\n",
    "        tf = \"Yes\"\n",
    "    return tf\n",
    "\n",
    "def get_book_chapter(df):\n",
    "    \"\"\"Returns rows that are only book chapters\"\"\"\n",
    "    print(f\"{get_book_chapter.__name__}: {get_book_chapter.__doc__}\")\n",
    "    bc = df[(df.work_type == 'book-chapter')].copy()\n",
    "    bc['container_title_flag'] = bc.apply(in_container_title, axis=1)\n",
    "    bc['title_flag'] = bc.apply(in_title, axis=1)\n",
    "    return bc\n",
    "\n",
    "def prepare_output_df(bc, filename = 'book_chapters.csv'):\n",
    "    \"\"\"processes dataframe column headings for better readability, outputs dataframe as a csv file\"\"\"\n",
    "    print(f\"{prepare_output_df.__name__}: {prepare_output_df.__doc__}\")\n",
    "    # re-ordering columns for readability\n",
    "    bc = bc[['DOI', 'separated_tokens', 'token_frac_refs', 'author', 'title', 'container_title', 'flag', 'title_flag', 'container_title_flag', 'member', 'ref_pge', 'total_reference_length']].copy()\n",
    "    # renaming columns and removing unnecessary columns\n",
    "    rename_cols = {'separated_tokens': \"most occuring token counted over all processed references\", \n",
    "    'token_frac_refs': \"Percentage of references in which the token(s) appears\", \n",
    "    'flag' :\"author flag\", \n",
    "    'ref_pge': \"Percentage of references that are processed compared to the total number of references in the article\",\n",
    "    'total_reference_length': \"Total no. of references\"}\n",
    "    bc.rename(columns=rename_cols, inplace=True)\n",
    "     # outputting file\n",
    "    try:\n",
    "        bc.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: \", e)\n",
    "    print(f\"CSV file located here: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7341226-395e-4511-812d-53656d160934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data_frame: generates dataframe, processes ISSNs, adds counts\n",
      "read_data: Reads parquet file and returns a dataframe\n",
      "get_book_chapter: Returns rows that are only book chapters\n",
      "prepare_output_df: processes dataframe column headings for better readability, outputs dataframe as a csv file\n",
      "CSV file located here: book_chapters.csv\n"
     ]
    }
   ],
   "source": [
    "df = prepare_data_frame()\n",
    "bc = get_book_chapter(df)\n",
    "prepare_output_df(bc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
