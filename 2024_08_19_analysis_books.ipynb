{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f25e542-b9b0-4d79-a4ca-98296e751ab6",
   "metadata": {},
   "source": [
    "#### Run all cells and it will generate a csv file\n",
    "#### This notebook generates a csv file of books where the most common token is present between 50 - 100% of the references found in its metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cfeb114-1bbc-4c57-88fa-2d72da77a56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# get parquet file from here: \n",
    "# Current data source in a S3 bucket: sneakedreferences/processable-references/run_2024_08_19/2024_8_19T15_18_19.parquet\n",
    "# down\n",
    "# The parquet file is downloaded to the local machine\n",
    "FILENAME = \"2024_8_19T15_18_19.parquet\"\n",
    "def read_data(parquet_filename = FILENAME):\n",
    "    \"\"\"Reads parquet file and returns a dataframe\"\"\"\n",
    "    print(f\"{read_data.__name__}: {read_data.__doc__}\")\n",
    "    df = pd.read_parquet(parquet_filename)\n",
    "    return df\n",
    "\n",
    "def rearrange(issn):\n",
    "    \"\"\"Re-arranges ISSN datastructure to a more readable format\"\"\"\n",
    "    data = list(map(lambda x: (f\"{x[0][1]}\", f\"{x[1][1]}\"),issn))\n",
    "    return data\n",
    "\n",
    "def split_issn(issn):\n",
    "    \"\"\"Splits the datastructure into its component issns\"\"\"\n",
    "    e_issn = None\n",
    "    p_issn = None\n",
    "    for i in issn:\n",
    "        if \"print\" in i:\n",
    "            p_issn = i[1]\n",
    "        elif \"electronic\" in i:\n",
    "            e_issn = i[1]\n",
    "    return p_issn, e_issn\n",
    "\n",
    "def fix_issn(row):\n",
    "    \"\"\"Splits the original structure from the filename to a more readable format\"\"\"\n",
    "    issn = row['issn']\n",
    "    first_pass_issn = rearrange(issn)\n",
    "    p_issn, e_issn = split_issn(first_pass_issn)\n",
    "    return p_issn, e_issn\n",
    "\n",
    "def separate_container_title(data):\n",
    "    \"\"\"Converting type to allow for easier grouping\"\"\"\n",
    "    title = data\n",
    "    if isinstance(data, np.ndarray):\n",
    "        title = \", \".join(data.tolist())\n",
    "    return title\n",
    "\n",
    "def prepare_data_frame(filename = FILENAME):\n",
    "    \"\"\"generates dataframe, processes ISSNs, adds counts\"\"\"\n",
    "    print(f\"{prepare_data_frame.__name__}: {prepare_data_frame.__doc__}\")\n",
    "    df = read_data(filename)\n",
    "    df[['print_issn', 'electronic_issn']] = df.apply(fix_issn, axis = 1, result_type='expand')\n",
    "    df['separated_tokens'] = df.token_vocabulary.apply(lambda x: \", \".join(sorted(x)))\n",
    "    df['container_title'] = df.container_title.apply(separate_container_title)\n",
    "    df['ref_pge'] = df.apply(lambda x: x['cleaned_references_length']/x['total_reference_length'], axis=1)\n",
    "    df.drop(columns=['issn'], inplace=True)\n",
    "    # group counts\n",
    "    df['token_counts_by_print_issn'] = df.groupby(['separated_tokens', 'print_issn'])['DOI'].transform('count')\n",
    "    df['token_counts_by_electronic_issn'] = df.groupby(['separated_tokens', 'electronic_issn'])['DOI'].transform('count')\n",
    "    return df\n",
    "\n",
    "def get_books(df):\n",
    "    \"\"\"Returns rows that are only books\"\"\"\n",
    "    print(f\"{get_books.__name__}: {get_books.__doc__}\")\n",
    "    books = df[df.work_type == 'book'].sort_values('token_frac_refs', ascending=False).copy()\n",
    "    return books\n",
    "\n",
    "def prepare_output_df(books, filename = 'books.csv'):\n",
    "    \"\"\"processes dataframe column headings for better readability, outputs dataframe as a csv file\"\"\"\n",
    "    print(f\"{prepare_output_df.__name__}: {prepare_output_df.__doc__}\")\n",
    "    # re-ordering columns for readability\n",
    "    books = books[['DOI', 'separated_tokens', 'token_frac_refs', 'author', 'flag', 'title',  'member', 'ref_pge', 'total_reference_length']].copy()\n",
    "    # renaming columns and removing unnecessary columns\n",
    "    rename_cols = {'separated_tokens': \"most occuring token counted over all processed references\", \n",
    "    'token_frac_refs': \"Percentage of references in which the token(s) appears\", \n",
    "    'flag' :\"author flag\", \n",
    "    'ref_pge': \"Percentage of references that are processed compared to the total number of references in the article\",\n",
    "    'total_reference_length': \"Total no. of references\"}\n",
    "    books.rename(columns=rename_cols, inplace=True)\n",
    "     # outputting file\n",
    "    try:\n",
    "        books.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: \", e)\n",
    "    print(f\"CSV file located here: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7341226-395e-4511-812d-53656d160934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data_frame: generates dataframe, processes ISSNs, adds counts\n",
      "read_data: Reads parquet file and returns a dataframe\n",
      "get_books: Returns rows that are only books\n",
      "prepare_output_df: processes dataframe column headings for better readability, outputs dataframe as a csv file\n",
      "CSV file located here: books.csv\n"
     ]
    }
   ],
   "source": [
    "df = prepare_data_frame()\n",
    "books = get_books(df)\n",
    "books = prepare_output_df(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767bb71-ec9f-4154-ab71-255634ecdd93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
