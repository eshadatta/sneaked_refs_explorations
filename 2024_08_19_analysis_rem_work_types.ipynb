{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f25e542-b9b0-4d79-a4ca-98296e751ab6",
   "metadata": {},
   "source": [
    "#### Run all cells and it will generate a csv file\n",
    "#### This notebook generates a csv file of various work types (proceedings articles, posted content, and other) where the most common token is present between 50 - 100% of the references found in its metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0cfeb114-1bbc-4c57-88fa-2d72da77a56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# get parquet file from here: \n",
    "# Current data source in a S3 bucket: sneakedreferences/processable-references/run_2024_08_19/2024_8_19T15_18_19.parquet\n",
    "# down\n",
    "# The parquet file is downloaded to the local machine\n",
    "FILENAME = \"2024_8_19T15_18_19.parquet\"\n",
    "def read_data(parquet_filename = FILENAME):\n",
    "    \"\"\"Reads parquet file and returns a dataframe\"\"\"\n",
    "    print(f\"{read_data.__name__}: {read_data.__doc__}\")\n",
    "    df = pd.read_parquet(parquet_filename)\n",
    "    return df\n",
    "\n",
    "def rearrange(issn):\n",
    "    \"\"\"Re-arranges ISSN datastructure to a more readable format\"\"\"\n",
    "    data = list(map(lambda x: (f\"{x[0][1]}\", f\"{x[1][1]}\"),issn))\n",
    "    return data\n",
    "\n",
    "def split_issn(issn):\n",
    "    \"\"\"Splits the datastructure into its component issns\"\"\"\n",
    "    e_issn = None\n",
    "    p_issn = None\n",
    "    for i in issn:\n",
    "        if \"print\" in i:\n",
    "            p_issn = i[1]\n",
    "        elif \"electronic\" in i:\n",
    "            e_issn = i[1]\n",
    "    return p_issn, e_issn\n",
    "\n",
    "def fix_issn(row):\n",
    "    \"\"\"Splits the original structure from the filename to a more readable format\"\"\"\n",
    "    issn = row['issn']\n",
    "    first_pass_issn = rearrange(issn)\n",
    "    p_issn, e_issn = split_issn(first_pass_issn)\n",
    "    return p_issn, e_issn\n",
    "\n",
    "def separate_container_title(data):\n",
    "    \"\"\"Converting type to allow for easier grouping\"\"\"\n",
    "    title = data\n",
    "    if isinstance(data, np.ndarray):\n",
    "        title = \", \".join(data.tolist())\n",
    "    return title\n",
    "\n",
    "def prepare_data_frame(filename = FILENAME):\n",
    "    \"\"\"generates dataframe, processes ISSNs, adds counts\"\"\"\n",
    "    print(f\"{prepare_data_frame.__name__}: {prepare_data_frame.__doc__}\")\n",
    "    df = read_data(filename)\n",
    "    df[['print_issn', 'electronic_issn']] = df.apply(fix_issn, axis = 1, result_type='expand')\n",
    "    df['separated_tokens'] = df.token_vocabulary.apply(lambda x: \", \".join(sorted(x)))\n",
    "    df['container_title'] = df.container_title.apply(separate_container_title)\n",
    "    df['ref_pge'] = df.apply(lambda x: x['cleaned_references_length']/x['total_reference_length'], axis=1)\n",
    "    df.drop(columns=['issn'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_specific_wt_df(df, work_type):\n",
    "    \"\"\"Returns rows that are only of the specified work type\"\"\"\n",
    "    print(f\"{get_specific_wt_df.__name__}: {get_specific_wt_df.__doc__}\")\n",
    "    wt_df = df[df.work_type == work_type].sort_values('token_frac_refs', ascending=False).copy()\n",
    "    return wt_df\n",
    "\n",
    "\n",
    "def prepare_output_df(results, columns, filename):\n",
    "    \"\"\"processes dataframe column headings for better readability, outputs dataframe as a csv file\"\"\"\n",
    "    print(f\"{prepare_output_df.__name__}: {prepare_output_df.__doc__}\")\n",
    "    # re-ordering columns for readability\n",
    "    results = results[columns].copy()\n",
    "    # renaming columns and removing unnecessary columns\n",
    "    rename_cols = {'separated_tokens': \"most occuring token counted over all processed references\", \n",
    "    'token_frac_refs': \"Percentage of references in which the token(s) appears\", \n",
    "    'flag' :\"author flag\", \n",
    "    'ref_pge': \"Percentage of references that are processed compared to the total number of references in the article\",\n",
    "    'total_reference_length': \"Total no. of references\"}\n",
    "    results.rename(columns=rename_cols, inplace=True)\n",
    "     # outputting file\n",
    "    try:\n",
    "        results.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: \", e)\n",
    "    print(f\"CSV file located here: {filename}\")\n",
    "\n",
    "def get_proceedings_articles(df):\n",
    "    columns = ['DOI', 'separated_tokens', 'token_frac_refs', 'author', 'flag', 'title',  'container_title','member', 'ref_pge', 'total_reference_length']\n",
    "    pa = get_specific_wt_df(df, \"proceedings-article\")\n",
    "    prepare_output_df(pa, columns, \"proceedings_articles.csv\")\n",
    "\n",
    "def get_posted_content(df):\n",
    "    columns = ['DOI', 'separated_tokens', 'token_frac_refs', 'author', 'flag', 'title', 'member', 'ref_pge', 'total_reference_length']\n",
    "    pc = get_specific_wt_df(df, \"posted-content\")\n",
    "    prepare_output_df(pc, columns, \"posted_content.csv\")\n",
    "\n",
    "def get_other(df):\n",
    "    columns = ['DOI', 'separated_tokens', 'token_frac_refs', 'author', 'flag', 'title', 'container_title', 'member', 'ref_pge', 'total_reference_length']\n",
    "    other = get_specific_wt_df(df, \"other\")\n",
    "    prepare_output_df(other, columns, \"other.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3079565-8e23-4069-a989-d00561fdbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from parquet file\n",
    "df = prepare_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6334f35-8e79-4394-95fc-2800e4492e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_specific_wt_df: Returns rows that are only of the specified work type\n",
      "prepare_output_df: processes dataframe column headings for better readability, outputs dataframe as a csv file\n",
      "CSV file located here: proceedings_articles2.csv\n"
     ]
    }
   ],
   "source": [
    "# Get proceedings articles\n",
    "get_proceedings_articles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8808727d-a0dd-418d-be85-c7d3457ef05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_specific_wt_df: Returns rows that are only of the specified work type\n",
      "prepare_output_df: processes dataframe column headings for better readability, outputs dataframe as a csv file\n",
      "CSV file located here: posted_content.csv\n"
     ]
    }
   ],
   "source": [
    "get_posted_content(df)\n",
    "# There are a lot of terms in this that are not authors. More research needs to be done to do this programmatically rather than manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cde614e-9ce1-4a04-9bf9-6f8813f1c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_specific_wt_df: Returns rows that are only of the specified work type\n",
      "prepare_output_df: processes dataframe column headings for better readability, outputs dataframe as a csv file\n",
      "CSV file located here: other.csv\n"
     ]
    }
   ],
   "source": [
    "get_other(df)\n",
    "# There are a lot of terms in this that are not authors. More research needs to be done to do this programmatically rather than manually"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
